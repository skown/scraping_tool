# Google SERPs Scraping Tool

## Description

Google SERPs Scraping Tool is an efficient, scalable solution designed to scrape Google Search Engine Results Pages (SERPs) for a large volume of keywords. With a user-friendly GUI built on Streamlit, this tool facilitates data collection for SEO analysis, keyword research, and market trends.

## Features

1. Large Scale Scraping: The tool is capable of scraping Google SERPs for a large amount of keywords.
2. GUI with Streamlit: The tool comes with a graphical user interface, making it easy and intuitive to use.
3. Data Analysis: By gathering comprehensive SERP data, this tool aids in performing detailed SEO analysis, keyword research, and understanding market trends.

## Requirements

1. Python 3.6 or above
2. Dependencies from the requirements.txt file

## Installation

1. Clone the repository

```bash
git clone https://github.com/skown/scraping_tool.git
```

2. Navigate to the cloned directory:

```bash
cd scraping_tool
```

3. Install the required Python packages:

```bash
pip install -r requirements.txt
```

## Usage

Here is how to use the scraping tool:

1. Run the following command to start the Streamlit app:

```bash
streamlit run app.py
```

2. Put keywords into the input box. Each keyword should be on a separate line. You can also upload a CSV file containing keywords.

3. After running the scraping tool, you can download the scraped data as a CSV file.

## Contributing

If you want to contribute to this project, feel free to create a fork of the repository, make your changes, and submit a pull request.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

## Support

If you encounter any issues or have any questions, please open an issue on GitHub. We'll do our best to assist.

## Acknowledgements

Thank you to all who have contributed to this project, provided feedback, or found it useful. Your support is greatly appreciated!
